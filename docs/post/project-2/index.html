<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    
    <title>Project 2: Mercado Libre Data Challenge 2020 | Lucas Komel</title>
    <meta name="viewport" content="width=device-width,minimum-scale=1">
    <meta name="description" content="El desafío es construir un modelo de Machine Learning para predecir la próxima compra de un usuario basándose en su historial de navegación.">
    <meta name="generator" content="Hugo 0.80.0" />
    
    
      <META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">
    

    

  
  
    <link rel="stylesheet" href="https://lucaskomel.github.io/portfolio/ananke/dist/main.css_5c99d70a7725bacd4c701e995b969fea.css" >
  




    
      

    

    
    
    <meta property="og:title" content="Project 2: Mercado Libre Data Challenge 2020" />
<meta property="og:description" content="El desafío es construir un modelo de Machine Learning para predecir la próxima compra de un usuario basándose en su historial de navegación." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://lucaskomel.github.io/portfolio/post/project-2/" />
<meta property="article:published_time" content="2021-02-16T11:00:59-04:00" />
<meta property="article:modified_time" content="2021-02-16T11:00:59-04:00" /><meta property="og:site_name" content="Lucas Komel" />
<meta itemprop="name" content="Project 2: Mercado Libre Data Challenge 2020">
<meta itemprop="description" content="El desafío es construir un modelo de Machine Learning para predecir la próxima compra de un usuario basándose en su historial de navegación.">
<meta itemprop="datePublished" content="2021-02-16T11:00:59-04:00" />
<meta itemprop="dateModified" content="2021-02-16T11:00:59-04:00" />
<meta itemprop="wordCount" content="1922">



<meta itemprop="keywords" content="" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Project 2: Mercado Libre Data Challenge 2020"/>
<meta name="twitter:description" content="El desafío es construir un modelo de Machine Learning para predecir la próxima compra de un usuario basándose en su historial de navegación."/>

	
  </head>

  <body class="ma0 avenir bg-near-white">

    
   
  

  
  
  <header class="cover bg-top" style="background-image: url('https://lucaskomel.github.io/portfolio/images/MercadoLibre/cajas.jpeg');">
    <div class="pb3-m pb6-l bg-black-60">
      <nav class="pv3 ph3 ph4-ns" role="navigation">
  <div class="flex-l justify-between items-center center">
    <a href="https://lucaskomel.github.io/portfolio/" class="f3 fw2 hover-white no-underline white-90 dib">
      
        Lucas Komel
      
    </a>
    <div class="flex-l items-center">
      

      
        <ul class="pl0 mr3">
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://lucaskomel.github.io/portfolio/about/" title="Acerca de page">
              Acerca de
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://lucaskomel.github.io/portfolio/contact/" title="Contacto page">
              Contacto
            </a>
          </li>
          
          <li class="list f5 f4-ns fw4 dib pr3">
            <a class="hover-white no-underline white-90" href="https://lucaskomel.github.io/portfolio/post/" title="Projects page">
              Projects
            </a>
          </li>
          
        </ul>
      
      







<a href="https://www.linkedin.com/in/lucaskomel/" target="_blank" class="link-transition linkedin link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" rel="noopener" aria-label="follow on LinkedIn——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>









    </div>
  </div>
</nav>

      <div class="tc-l pv6 ph3 ph4-ns">
        
          <h1 class="f2 f1-l fw2 white-90 mb0 lh-title">Project 2: Mercado Libre Data Challenge 2020</h1>
          
            <h2 class="fw1 f5 f3-l white-80 measure-wide-l center lh-copy mt3 mb4">
              El desafío es construir un modelo de Machine Learning para predecir la próxima compra de un usuario basándose en su historial de navegación.
            </h2>
          
        
      </div>
    </div>
  </header>



    <main class="pb7" role="main">
      
  
  <article class="flex-l flex-wrap justify-between mw8 center ph3">
    <header class="mt4 w-100">
      <aside class="instapaper_ignoref b helvetica tracked">
          
        PROJECTS
      </aside>
      




  <div id="sharing" class="mt3">

    
    <a href="https://www.facebook.com/sharer.php?u=https://lucaskomel.github.io/portfolio/post/project-2/" class="facebook no-underline" aria-label="share on Facebook">
      <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M28.765,50.32h6.744V33.998h4.499l0.596-5.624h-5.095  l0.007-2.816c0-1.466,0.14-2.253,2.244-2.253h2.812V17.68h-4.5c-5.405,0-7.307,2.729-7.307,7.317v3.377h-3.369v5.625h3.369V50.32z   M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;"/></svg>

    </a>

    
    
    <a href="https://twitter.com/share?url=https://lucaskomel.github.io/portfolio/post/project-2/&amp;text=Project%202:%20Mercado%20Libre%20Data%20Challenge%202020" class="twitter no-underline" aria-label="share on Twitter">
      <svg height="32px"  style="enable-background:new 0 0 67 67;" version="1.1" viewBox="0 0 67 67" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M37.167,22.283c-2.619,0.953-4.274,3.411-4.086,6.101  l0.063,1.038l-1.048-0.127c-3.813-0.487-7.145-2.139-9.974-4.915l-1.383-1.377l-0.356,1.017c-0.754,2.267-0.272,4.661,1.299,6.271  c0.838,0.89,0.649,1.017-0.796,0.487c-0.503-0.169-0.943-0.296-0.985-0.233c-0.146,0.149,0.356,2.076,0.754,2.839  c0.545,1.06,1.655,2.097,2.871,2.712l1.027,0.487l-1.215,0.021c-1.173,0-1.215,0.021-1.089,0.467  c0.419,1.377,2.074,2.839,3.918,3.475l1.299,0.444l-1.131,0.678c-1.676,0.976-3.646,1.526-5.616,1.568  C19.775,43.256,19,43.341,19,43.405c0,0.211,2.557,1.397,4.044,1.864c4.463,1.377,9.765,0.783,13.746-1.568  c2.829-1.673,5.657-5,6.978-8.221c0.713-1.716,1.425-4.851,1.425-6.354c0-0.975,0.063-1.102,1.236-2.267  c0.692-0.678,1.341-1.419,1.467-1.631c0.21-0.403,0.188-0.403-0.88-0.043c-1.781,0.636-2.033,0.551-1.152-0.402  c0.649-0.678,1.425-1.907,1.425-2.267c0-0.063-0.314,0.042-0.671,0.233c-0.377,0.212-1.215,0.53-1.844,0.72l-1.131,0.361l-1.027-0.7  c-0.566-0.381-1.361-0.805-1.781-0.932C39.766,21.902,38.131,21.944,37.167,22.283z M33,64C16.432,64,3,50.569,3,34S16.432,4,33,4  s30,13.431,30,30S49.568,64,33,64z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/></svg>

    </a>

    
    <a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://lucaskomel.github.io/portfolio/post/project-2/&amp;title=Project%202:%20Mercado%20Libre%20Data%20Challenge%202020" class="linkedin no-underline" aria-label="share on LinkedIn">
      <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

    </a>
  </div>


      <h1 class="f1 athelas mt3 mb1">Project 2: Mercado Libre Data Challenge 2020</h1>
      
      
      <time class="f6 mv4 dib tracked" datetime="2021-02-16T11:00:59-04:00">February 16, 2021</time>

      
      
    </header>
    <div class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-two-thirds-l"><p><em><strong>Proyecto en desarrollo&hellip;</strong></em></p>
<p>Mercado Libre presenta millones de publicaciones de productos y servicios. Los usuarios navegan a través de ellas en incontables ocasiones, buscando lo que quieren comprar o simplemente para encontrar ideas para una próxima compra.</p>
<p>Entender mejor lo que puede llegar a interesarles es crítico para el negocio, ya que así es posible ayudarlos a encontrar lo que están buscando, brindándoles recomendaciones personalizadas basadas en las publicaciones que son más cercanas a las necesidades y preferencias de cada usuario.</p>
<figure>
    <img src="https://lucaskomel.github.io/portfolio/images/MercadoLibre/cajas-2.jpeg"/> 
</figure>

<p>Dado el registro de un período de navegación de un usuario, buscaremos predecir los diez (10) items más probables a ser elegidos en su próxima compra.</p>
<p>Para este proyecto trabajaremos con un <strong>dataset anonimizado</strong> con data sobre compras en Brasil y México. Este dataset fue publicado por Mercado Libre para que cualquiera pueda usarlo para explorar, practicar y aprender a modelar este tipo de problemas, con data que nunca antes había estado disponible en Latinoamérica.</p>
<p><strong>Acerca de Mercado Libre</strong></p>
<p>Mercado Libre es la compañía líder de e-commerce y fintech de Latinoamérica. Es una compañía pionera en e-commerce, basada en una plataforma donde los usuarios compran, venden, publicitan, entregan, financian y pagan bienes y servicios a través de Internet.</p>
<p><strong>Datasets</strong></p>
<p>La organización de la competencia nos provee de dos datasets: <strong>train_dataset.jl.gz</strong> y <strong>test_dataset.jl.gz</strong></p>
<p>La siguiente imágen muestra cómo se ve una fila de los mismos:</p>
<figure>
    <img src="https://lucaskomel.github.io/portfolio/images/MercadoLibre/data_json_example.png"/> 
</figure>

<p>En ambos, cada fila representa una compra de un usuario y tiene dos atributos asociados: <strong>user_history</strong> e <strong>item_bought</strong>.</p>
<table>
<thead>
<tr>
<th>Atributos</th>
<th>Descripción</th>
</tr>
</thead>
<tbody>
<tr>
<td>user_history</td>
<td><em>Una semana de navegación previa y hasta 2 hs. antes de la compra.</em></td>
</tr>
<tr>
<td>item_bought</td>
<td><em>Número único de identificación del item comprado. Esta es la variable target.</em></td>
</tr>
</tbody>
</table>
<p>El campo <strong>user_history</strong> comprende una lista de 3-tuplas. Una tupla es una lista ordenada de valores agrupados.</p>
<p>Cada 3-tupla representa un evento en el historial de navegación y contiene lo siguiente:</p>
<p><strong>(event_type, event_timestamp, event_info)</strong></p>
<table>
<thead>
<tr>
<th>Elemento</th>
<th>Descripción</th>
</tr>
</thead>
<tbody>
<tr>
<td>event_type</td>
<td><em>Puede ser view o search.</em></td>
</tr>
<tr>
<td>event_timestamp</td>
<td><em>Marca temporal de cuando el evento tuvo lugar.</em></td>
</tr>
<tr>
<td>event_info</td>
<td><em>Si event_type es view, este campo contiene el item_id. de la publicación correspondiente, de otra forma contiene la query string correspondiente al evento de search.</em></td>
</tr>
</tbody>
</table>
<p>La columna <strong>item_bought</strong> no está en el dataset de entrenamiento, ya que este constituye el target variable.</p>
<p><strong>Datos Extras</strong></p>
<p>En el archivo <strong>items_data.jl.gz</strong> hay información que puede ser usada como features en los modelos. Este archivo contiene la metadata de los ítems. Los siguientes campos están disponibles:</p>
<table>
<thead>
<tr>
<th>Atributo</th>
<th>Descripción</th>
</tr>
</thead>
<tbody>
<tr>
<td>Item_id</td>
<td><em>ID único de la publicación. Este campo está ofuscado.</em></td>
</tr>
<tr>
<td>Title</td>
<td><em>Título de la publicación.</em></td>
</tr>
<tr>
<td>Price</td>
<td><em>Precio (USD).</em></td>
</tr>
<tr>
<td>Category_id</td>
<td><em>ID de Categoría hoja.</em></td>
</tr>
<tr>
<td>Product_id</td>
<td><em>ID de producto para la publicación. El campo puede ser null para algunas publicaciones.</em></td>
</tr>
<tr>
<td>Domain_id</td>
<td><em>ID de dominio. Un dominio es una agrupación de publicaciones. No tiene una relación explícita con el árbol de categoría.</em></td>
</tr>
<tr>
<td>Condition</td>
<td><em>Si la lista se refiere a un ítem nuevo o usado.</em></td>
</tr>
</tbody>
</table>
<p>Adicionalmente el campo <strong>Category_path_from_root</strong> nos otorga información adicional sobre con que productos estamos trabajando.</p>
<p><strong>Métricas de Evaluación</strong></p>
<p>Los modelos serán evaluados utilizando el promedio de <em><strong>NDCG (Normalized Discounted Cumulative Gain o Ganancia Acumulada Descontada y Normalizada)</strong></em>.</p>
<p><em><strong>NDCG</strong></em> es un método popular para medir la calidad de los resultados de un set. La métrica puede ser fácilmente adaptada al dominio de las recomendaciones.</p>
<p>Este método se basa en las siguientes premisas:</p>
<ul>
<li>
<p><strong>Ganancia Acumulada:</strong> Las recomendaciones muy relevantes son más útiles que las recomendaciones algo relevantes, que son a su vez más útiles que recomendaciones irrelevantes (es decir, queremos recomendar publicaciones relevantes al usuario).</p>
</li>
<li>
<p><strong>Descuento:</strong> Las recomendaciones relevantes son más útiles cuando aparecen antes en el set de recomendaciones (es decir, el orden importa).</p>
</li>
<li>
<p><strong>Normalización:</strong> La métrica debe estar en el intervalo [0,1].</p>
</li>
</ul>
<p>La siguiente fórmula corresponde a cómo se computa <em>NDCG</em>:</p>
<figure>
    <img src="https://lucaskomel.github.io/portfolio/images/MercadoLibre/ndcg.png"/> 
</figure>

<p>En otras palabras, <em>NDCG</em> es solo la <em>Ganancia Acumulada Descontada</em> dividida por la <em>Ganancia Acumulada Descontada</em> del conjunto de recomendaciones ideal.</p>
<p>Para calcular la <em>Ganancia Acumulada Descontada</em> podríamos sumar la relevancia de cada elemento en el conjunto de recomendaciones (esto nos dará la <em>Ganancia Acumulada</em>). El problema con esta métrica es que no tiene en cuenta la forma en que se ordenan los elementos recomendados. Así, recomendar el artículo adecuado en la 10° posición será tan valorado como hacerlo en la 1° posición.</p>
<p>No queremos que esto suceda, es por eso que descontamos la <em>Ganancia Acumulada</em> ponderando cada relevancia inversamente a su posición.</p>
<p>El <em>Discounted Cumulative Gain</em> resulta en algo como esto:</p>
<figure>
    <img src="https://lucaskomel.github.io/portfolio/images/MercadoLibre/dcg-2.png"/> 
</figure>

<p>Usando logaritmos para enfatizar el efecto:</p>
<figure>
    <img src="https://lucaskomel.github.io/portfolio/images/MercadoLibre/dcg.png"/> 
</figure>

<ul>
<li>
<p><em>k</em> representa cada uno de los ítems que predecimos.</p>
</li>
<li>
<p><em>rel(i)</em> representa la relevancia.</p>
</li>
<li>
<p>La Ganancia <em>G</em> es una función creciente ya que cuanto más relevante es el ítem para nosotros, más grande va a ser la ganancia.</p>
</li>
<li>
<p>El Descuento <em>D</em> es una función decreciente.</p>
</li>
<li>
<p>Se premia la relevancia y se castiga la posición.</p>
</li>
</ul>
<p>Una vez calculada el <em>DCG</em> es necesario transformarlo para poder compararlo.</p>
<p>Esto se logra con la <em>Normalized Discounted Cumulative Gain:</em></p>
<figure>
    <img src="https://lucaskomel.github.io/portfolio/images/MercadoLibre/nDCG-k.png"/> 
</figure>

<p>Lo que se hace es dividir el <em>DCG</em> sobre el <em>DCG</em> de la predicción ideal, la <em>IDCG@k</em>. Esto nos dará un valor entre 0 y 1, donde a mayor valor, mejor será indicador.</p>
<p>Finalmente, necesitamos definir la relevancia de alguna manera. Para este problema se ha decidido que la <em><strong>relevancia de predecir un determinado artículo y^ para una compra correspondiente y viene dada por la siguiente función:</strong></em></p>
<figure>
    <img src="https://lucaskomel.github.io/portfolio/images/MercadoLibre/implementacion-ndcg.png"/> 
</figure>

<p>Donde <em>y^</em> es la predicción e <em>y</em> es el artículo que el usuario compró.</p>
<p>Esto significa que:</p>
<ul>
<li>
<p>Si adivinamos el item_id de la compra objetivo del usuario, obtendremos una relevancia de 12 para esa recomendación en su conjunto de recomendaciones.</p>
</li>
<li>
<p>En cambio, si la predicción no coincide con el ID de artículo correcto, pero corresponde al mismo dominio, obtendrá 1 punto de relevancia.</p>
</li>
<li>
<p>En caso de que no coincida con ninguno de ellos, su relevancia será 0.</p>
</li>
</ul>
<p><em>El conjunto de recomendaciones ideal será aquel compuesto por el mismo ID de artículo que el objetivo en la primera posición, seguido de 9 IDs de artículos que pertenezcan al mismo ID de dominio que el artículo objetivo en las recomendaciones restantes.</em></p>
<p><strong>Formato de Resultados</strong></p>
<p>Los resultados se registran en un archivo .csv con diez ID de elemento por fila, separados por comas, y sin cabecera. Cada uno de estos ID de elemento sería parte de un conjunto de recomendaciones para el número de fila correspondiente en el conjunto de evaluación. Asumiremos que las predicciones están ordenadas de la misma manera que el conjunto de datos de prueba original.</p>
<p>Si cualquier fila tiene menos de diez ítems, la recomendación seguirá siendo válida, pero recibirá relevancia cero para los ítems que no están en el set de recomendaciones.</p>
<p>La forma en que clasifican los ID de artículo dentro de cada fila es importante: el primer ID de artículo de la fila debe ser la compra futura más probable, el segundo ID de artículo de la fila debe ser la segunda compra futura más probable y así sucesivamente.</p>
<p>Por último, es importante notar que en un set de recomendaciones (ej. una fila), los item-ids deberían ser únicos (de otra forma, podríamos tener una puntuación mayor a 1).</p>
<p><strong>Algunas estrategias de modelado</strong></p>
<p><strong>Estrategia 1: Multiclass</strong></p>
<p>Esta estrategia es la más rápida y fácil de implementar, el modelo recibe como input el historial de navegación y la metadata, y arroja como output para cada ítem posible la probabilidad de que el usuario haya terminado comprando ese ítem. Una vez que tenemos esto recomendamos en orden descendente aquellos con mayor probabilidad.</p>
<figure>
    <img src="https://lucaskomel.github.io/portfolio/images/MercadoLibre/multiclass.png"/> 
</figure>

<p>Las ventajas de este método son:</p>
<ul>
<li>Es fácil de implementar.</li>
<li>No es necesario armar un dataset custom.</li>
<li>No es necesario hacer mucha ingeniería de features.</li>
<li>Nos da un score para cada item del inventario.</li>
</ul>
<p>Sus desventajas son:</p>
<ul>
<li>La función utilizada para calcular las probabilidades se denomina <em>softmax</em> y es muy costosa en términos computacionales cuando el número de categorías es grande, como en este caso.</li>
<li>Muchas veces nuestro dataset no tiene suficientes ejemplos de todas las categorías para que el modelo &ldquo;aprenda&rdquo;.</li>
</ul>
<p><strong>Estrategia 2: Candidate generator + ranker (aka Candidates vs. Noise)</strong></p>
<p>Esta estrategia combina dos partes, un generador de candidatos que van a ser recomendados, y luego un ranker, que les pone un score o los ordena.</p>
<figure>
    <img src="https://lucaskomel.github.io/portfolio/images/MercadoLibre/candidate-ranker.png"/> 
</figure>

<p>En principio tenemos miles de candidatos y tenemos que scorear todos, pero si queremos asignarle un score a cada uno utilizando la metadata esto es muy costoso computacionalmente. El generador tiene la función de filtrar ejemplos que no tengan sentido, como recomendar una reposera a alguien que su historial muestra que únicamente estuvo mirando bicicletas.</p>
<p>Una vez que los candidatos han sido filtrados, podemos usar un modelo de Machine Learning para ordenarlos.</p>
<p>Las ventajas de este método son:</p>
<ul>
<li>Podemos usar heurísticas sencillas como generadores y mejorarlas en la etapa de ranker una vez que tenemos algunos pocos candidatos.</li>
<li>Evitamos el problema de softmax, utilizando funciones más simples.</li>
</ul>
<p>Desventajas:</p>
<ul>
<li>No es obvio cómo diseñar el ranker.</li>
<li>Generalmente necesitamos armar un dataset custom para poder abordar la etapa del ranker.</li>
</ul>
<p>Este tipo de modelos se llaman de <em>Candidates vs. Noise</em> ya que consideramos a los productos que el usuario si terminó comprando como la <em>señal o candidatos</em>, y a los productos que no terminó comprando como el <em>ruido</em>.</p>
<p><strong>Estrategia 3: Custom Model + Custom Loss</strong></p>
<p>En esta estrategia utilizamos un modelo con una función de pérdida customizada.</p>
<p>La función <em>softmax</em> que traduce los resultados del modelo en probabilidades se representa de la siguiente forma:</p>
<figure>
    <img src="https://lucaskomel.github.io/portfolio/images/MercadoLibre/custom-model.png"/> 
</figure>

<p>La probabilidad de una clase <em>w</em> dado un contexto <em>c</em> es el cociente que podemos ver a la derecha de la ecuación.</p>
<p><em>h</em> es el último layer del modelo que está oculto.</p>
<p><em>v'</em> es el último embedding calculado con los últimos pesos.</p>
<p>El problema lo tenemos en el denominador, dado que es una sumatoria que recorre todos los ítems del inventario de Mercado Libre, lo que tiene un costo computacional muy grande.</p>
<p>En los modelos de Deep Learning usan la salida del softmax para calcular una función de pérdida, la cual el modelo debe optimizar y llevarla a un valor lo más chico posible para entrenarlo.</p>
<p>Para evitar el problema de la <em>softmax</em> una forma es hacer una <em>softmax aproximada</em> que es el caso del <em>Hierarchical SOFTMAX</em>, o evitarla completamente como es el caso del <em>Negative Sampling</em> o el <em>Noise Contrasting Estimation (NCE)</em>. En estos últimos métodos se utilizan otras funciones de pérdida.</p>
<p><strong>Baselines</strong></p>
<p>Un baseline es un <strong>modelo simple</strong> que nos sirve de punto de partida para comparar contra modelos más elaborados. Un ejemplo es un modelo que recomienda los ítems que visitó el usuario. Si un modelo elaborado no le gana al baseline, no tiene mucho sentido usarlo para hacer predicciones.</p>
<p>Otro posible baseline podría ser los ítems más vendidos del dominio que más visitó el usuario donde recomendamos los ítems más vendidos del dominio que más views tuvo. Debemos seguir los siguientes pasos:</p>
<ol>
<li>Buscamos el dominio que más miró el usuario.</li>
<li>Para ese dominio, buscamos los 10 ítems más vendidos</li>
<li>Si hay menos de 10, rellenamos al azar.</li>
</ol>
<p><strong>Aplicación de los métodos:</strong></p>
<p>Para iterar podemos:</p>
<ul>
<li>Usar los baselines para medir nuevos modelos.</li>
<li>Usar los baselines como generadores de candidatos a ser evaluados por un ranker (hacer el ranker es lo más complicado).</li>
<li>Combinar baselines, incluso utilizando Machine Learning.</li>
</ul>
<p>Otra forma de atacar este problema podría ser concentrarnos en acertar los dominios, es decir en vez de concentrarnos en adivinar el ítem que el usuario va a comprar, enfocarnos en analizar de qué dominio es el ítem que el usuario va a comprar.</p>
<figure>
    <img src="https://lucaskomel.github.io/portfolio/images/MercadoLibre/logo-meli.jpg"/> 
</figure>

<p><strong>Librerias de Python utilizadas:</strong></p>
<ul>
<li><em>Numpy</em></li>
<li><em>Pandas</em></li>
<li><em>Seaborn</em></li>
<li><em>Matplotlib</em></li>
<li><em>Scikit-learn</em></li>
<li><em>Keras</em></li>
<li><em>Pytorch</em></li>
<li><em>LightGBM</em></li>
</ul>
<figure>
    <img src="https://lucaskomel.github.io/portfolio/images/Tools/python-logo.png"/> 
</figure>

<p><strong>Agradecimientos y Referencias:</strong></p>
<ul>
<li><em><a href="https://www.mercadolibre.com.ar/">Mercado Libre Argentina</a></em></li>
<li><em><a href="https://ideas.mercadolibre.com/ar/">Ideas Mercado Libre</a></em></li>
<li><em><a href="https://ml-challenge.mercadolibre.com/">Mercado Libre Data Challenge 2020</a></em></li>
<li><em><a href="https://www.medium.com/mercadolibre-tech">Mercado Libre Tech - Experiences and reflections from the Tech team</a></em></li>
</ul>
<ul class="pa0">
  
</ul>
<div class="mt6 instapaper_ignoref">
      
      
      </div>
    </div>

    <aside class="w-30-l mt6-l">




</aside>

  </article>

    </main>
    <footer class="bg-black bottom-0 w-100 pa3" role="contentinfo">
  <div class="flex justify-between">
  <a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href="https://lucaskomel.github.io/portfolio/" >
    &copy;  Lucas Komel 2021 
  </a>
    <div>







<a href="https://www.linkedin.com/in/lucaskomel/" target="_blank" class="link-transition linkedin link dib z-999 pt3 pt0-l mr1" title="LinkedIn link" rel="noopener" aria-label="follow on LinkedIn——Opens in a new window">
  <svg  height="32px"  style="enable-background:new 0 0 65 65;" version="1.1" viewBox="0 0 65 65" width="32px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
  <path d="M50.837,48.137V36.425c0-6.275-3.35-9.195-7.816-9.195  c-3.604,0-5.219,1.983-6.119,3.374V27.71h-6.79c0.09,1.917,0,20.427,0,20.427h6.79V36.729c0-0.609,0.044-1.219,0.224-1.655  c0.49-1.22,1.607-2.483,3.482-2.483c2.458,0,3.44,1.873,3.44,4.618v10.929H50.837z M22.959,24.922c2.367,0,3.842-1.57,3.842-3.531  c-0.044-2.003-1.475-3.528-3.797-3.528s-3.841,1.524-3.841,3.528c0,1.961,1.474,3.531,3.753,3.531H22.959z M34,64  C17.432,64,4,50.568,4,34C4,17.431,17.432,4,34,4s30,13.431,30,30C64,50.568,50.568,64,34,64z M26.354,48.137V27.71h-6.789v20.427  H26.354z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>

<span class="new-window"><svg  height="8px"  style="enable-background:new 0 0 1000 1000;" version="1.1" viewBox="0 0 1000 1000" width="8px" xml:space="preserve" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" >
<path d="M598 128h298v298h-86v-152l-418 418-60-60 418-418h-152v-86zM810 810v-298h86v298c0 46-40 86-86 86h-596c-48 0-86-40-86-86v-596c0-46 38-86 86-86h298v86h-298v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:;"/>
</svg>
</span></a>








</div>
  </div>
</footer>

  </body>
</html>
